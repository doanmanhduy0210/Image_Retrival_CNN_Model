{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import adam \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Convolution2D\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers \n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# from tensorflow.keras.models import BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D,ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers  import BatchNormalization\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator (): \n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    y_train = np_utils.to_categorical (y_train, 10)\n",
    "    x_train = x_train.reshape (x_train.shape[0], 28, 28, 1)\n",
    "    x_test  = x_test.reshape (x_test.shape[0],28,28,1)\n",
    "    x_train = x_train.astype('float32') \n",
    "    x_test  = x_test.astype('float32')\n",
    "    x_train  /=255 \n",
    "    x_test  /=255 \n",
    "    while True: \n",
    "        for i in range (1875): \n",
    "            if i % 125 is 0:\n",
    "                print(\" Processing i = {}\".format(i))\n",
    "            yield x_train[i*32: (i+1)*32], y_train[i*32:(i+1)*32]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add (Conv2D(32, (3,3), activation='relu',padding= 'same',input_shape = (28,28,1)))\n",
    "model.add (Convolution2D(32,(3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add (Conv2D(64, (3,3), activation='relu',padding= 'same',input_shape = (28,28,1)))\n",
    "model.add (Convolution2D(64,(3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu')) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 266,410\n",
      "Trainable params: 266,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "import math\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32 \n",
    "epoch = 5\n",
    "n_classes = 10\n",
    "\n",
    "sgd = optimizers.SGD( lr= 0.01, decay = 1e-6, momentum = 0.9)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                  patience=4, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/manhduy/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      " Processing i = 0\n",
      " 113/1875 [>.............................] - ETA: 1:05 - loss: 0.0030 - accuracy: 0.9989 Processing i = 125\n",
      " 239/1875 [==>...........................] - ETA: 59s - loss: 0.0034 - accuracy: 0.9989 Processing i = 250\n",
      " 363/1875 [====>.........................] - ETA: 55s - loss: 0.0032 - accuracy: 0.9989 Processing i = 375\n",
      " 488/1875 [======>.......................] - ETA: 51s - loss: 0.0029 - accuracy: 0.9990 Processing i = 500\n",
      " 614/1875 [========>.....................] - ETA: 46s - loss: 0.0028 - accuracy: 0.9990 Processing i = 625\n",
      " 738/1875 [==========>...................] - ETA: 41s - loss: 0.0025 - accuracy: 0.9991 Processing i = 750\n",
      " 864/1875 [============>.................] - ETA: 37s - loss: 0.0027 - accuracy: 0.9990 Processing i = 875\n",
      " 988/1875 [==============>...............] - ETA: 32s - loss: 0.0026 - accuracy: 0.9991 Processing i = 1000\n",
      "1114/1875 [================>.............] - ETA: 27s - loss: 0.0025 - accuracy: 0.9991 Processing i = 1125\n",
      "1238/1875 [==================>...........] - ETA: 23s - loss: 0.0025 - accuracy: 0.9991 Processing i = 1250\n",
      "1364/1875 [====================>.........] - ETA: 18s - loss: 0.0025 - accuracy: 0.9991 Processing i = 1375\n",
      "1488/1875 [======================>.......] - ETA: 13s - loss: 0.0024 - accuracy: 0.9991 Processing i = 1500\n",
      "1613/1875 [========================>.....] - ETA: 9s - loss: 0.0024 - accuracy: 0.9991 Processing i = 1625\n",
      "1739/1875 [==========================>...] - ETA: 4s - loss: 0.0023 - accuracy: 0.9991 Processing i = 1750\n",
      "1863/1875 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 Processing i = 0\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 2/5\n",
      "   5/1875 [..............................] - ETA: 1:03 - loss: 0.0044 - accuracy: 0.9988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manhduy/.local/lib/python3.6/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 113/1875 [>.............................] - ETA: 1:04 - loss: 0.0018 - accuracy: 0.9993 Processing i = 125\n",
      " 238/1875 [==>...........................] - ETA: 58s - loss: 0.0021 - accuracy: 0.9992 Processing i = 250\n",
      " 363/1875 [====>.........................] - ETA: 53s - loss: 0.0019 - accuracy: 0.9992 Processing i = 375\n",
      " 488/1875 [======>.......................] - ETA: 49s - loss: 0.0020 - accuracy: 0.9993 Processing i = 500\n",
      " 614/1875 [========>.....................] - ETA: 44s - loss: 0.0020 - accuracy: 0.9993 Processing i = 625\n",
      " 739/1875 [==========>...................] - ETA: 40s - loss: 0.0019 - accuracy: 0.9993 Processing i = 750\n",
      " 863/1875 [============>.................] - ETA: 35s - loss: 0.0019 - accuracy: 0.9993 Processing i = 875\n",
      " 989/1875 [==============>...............] - ETA: 30s - loss: 0.0018 - accuracy: 0.9993 Processing i = 1000\n",
      "1113/1875 [================>.............] - ETA: 26s - loss: 0.0018 - accuracy: 0.9993 Processing i = 1125\n",
      "1239/1875 [==================>...........] - ETA: 21s - loss: 0.0017 - accuracy: 0.9994 Processing i = 1250\n",
      "1363/1875 [====================>.........] - ETA: 17s - loss: 0.0017 - accuracy: 0.9993 Processing i = 1375\n",
      "1489/1875 [======================>.......] - ETA: 13s - loss: 0.0017 - accuracy: 0.9993 Processing i = 1500\n",
      "1613/1875 [========================>.....] - ETA: 8s - loss: 0.0017 - accuracy: 0.9993 Processing i = 1625\n",
      "1739/1875 [==========================>...] - ETA: 4s - loss: 0.0017 - accuracy: 0.9994 Processing i = 1750\n",
      "1863/1875 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994 Processing i = 0\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 3/5\n",
      " 113/1875 [>.............................] - ETA: 1:01 - loss: 0.0012 - accuracy: 0.9996 Processing i = 125\n",
      " 239/1875 [==>...........................] - ETA: 57s - loss: 0.0016 - accuracy: 0.9995 Processing i = 250\n",
      " 363/1875 [====>.........................] - ETA: 53s - loss: 0.0016 - accuracy: 0.9995 Processing i = 375\n",
      " 488/1875 [======>.......................] - ETA: 48s - loss: 0.0016 - accuracy: 0.9995 Processing i = 500\n",
      " 613/1875 [========>.....................] - ETA: 44s - loss: 0.0016 - accuracy: 0.9994 Processing i = 625\n",
      " 739/1875 [==========>...................] - ETA: 39s - loss: 0.0016 - accuracy: 0.9994 Processing i = 750\n",
      " 863/1875 [============>.................] - ETA: 35s - loss: 0.0016 - accuracy: 0.9994 Processing i = 875\n",
      " 989/1875 [==============>...............] - ETA: 31s - loss: 0.0016 - accuracy: 0.9994 Processing i = 1000\n",
      "1114/1875 [================>.............] - ETA: 26s - loss: 0.0017 - accuracy: 0.9994 Processing i = 1125\n",
      "1238/1875 [==================>...........] - ETA: 22s - loss: 0.0017 - accuracy: 0.9994 Processing i = 1250\n",
      "1364/1875 [====================>.........] - ETA: 17s - loss: 0.0017 - accuracy: 0.9994 Processing i = 1375\n",
      "1488/1875 [======================>.......] - ETA: 13s - loss: 0.0017 - accuracy: 0.9994 Processing i = 1500\n",
      "1614/1875 [========================>.....] - ETA: 8s - loss: 0.0017 - accuracy: 0.9994 Processing i = 1625\n",
      "1739/1875 [==========================>...] - ETA: 4s - loss: 0.0017 - accuracy: 0.9994 Processing i = 1750\n",
      "1863/1875 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994 Processing i = 0\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 4/5\n",
      " 113/1875 [>.............................] - ETA: 55s - loss: 9.7849e-04 - accuracy: 0.9997 Processing i = 125\n",
      " 239/1875 [==>...........................] - ETA: 51s - loss: 0.0016 - accuracy: 0.9995 Processing i = 250\n",
      " 363/1875 [====>.........................] - ETA: 47s - loss: 0.0015 - accuracy: 0.9995 Processing i = 375\n",
      " 489/1875 [======>.......................] - ETA: 43s - loss: 0.0015 - accuracy: 0.9995 Processing i = 500\n",
      " 613/1875 [========>.....................] - ETA: 40s - loss: 0.0014 - accuracy: 0.9995 Processing i = 625\n",
      " 739/1875 [==========>...................] - ETA: 36s - loss: 0.0014 - accuracy: 0.9995 Processing i = 750\n",
      " 863/1875 [============>.................] - ETA: 32s - loss: 0.0013 - accuracy: 0.9995 Processing i = 875\n",
      " 989/1875 [==============>...............] - ETA: 28s - loss: 0.0014 - accuracy: 0.9995 Processing i = 1000\n",
      "1113/1875 [================>.............] - ETA: 24s - loss: 0.0014 - accuracy: 0.9995 Processing i = 1125\n",
      "1239/1875 [==================>...........] - ETA: 20s - loss: 0.0014 - accuracy: 0.9995 Processing i = 1250\n",
      "1363/1875 [====================>.........] - ETA: 16s - loss: 0.0014 - accuracy: 0.9995 Processing i = 1375\n",
      "1488/1875 [======================>.......] - ETA: 12s - loss: 0.0014 - accuracy: 0.9995 Processing i = 1500\n",
      "1613/1875 [========================>.....] - ETA: 8s - loss: 0.0014 - accuracy: 0.9995 Processing i = 1625\n",
      "1739/1875 [==========================>...] - ETA: 4s - loss: 0.0014 - accuracy: 0.9995 Processing i = 1750\n",
      "1863/1875 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995 Processing i = 0\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 5/5\n",
      " 113/1875 [>.............................] - ETA: 1:01 - loss: 0.0018 - accuracy: 0.9993 Processing i = 125\n",
      " 239/1875 [==>...........................] - ETA: 59s - loss: 0.0018 - accuracy: 0.9993 Processing i = 250\n",
      " 364/1875 [====>.........................] - ETA: 55s - loss: 0.0017 - accuracy: 0.9993 Processing i = 375\n",
      " 488/1875 [======>.......................] - ETA: 51s - loss: 0.0016 - accuracy: 0.9993 Processing i = 500\n",
      " 614/1875 [========>.....................] - ETA: 47s - loss: 0.0016 - accuracy: 0.9993 Processing i = 625\n",
      " 738/1875 [==========>...................] - ETA: 42s - loss: 0.0016 - accuracy: 0.9994 Processing i = 750\n",
      " 863/1875 [============>.................] - ETA: 37s - loss: 0.0017 - accuracy: 0.9994 Processing i = 875\n",
      " 988/1875 [==============>...............] - ETA: 33s - loss: 0.0016 - accuracy: 0.9994 Processing i = 1000\n",
      "1113/1875 [================>.............] - ETA: 28s - loss: 0.0016 - accuracy: 0.9994 Processing i = 1125\n",
      "1239/1875 [==================>...........] - ETA: 23s - loss: 0.0016 - accuracy: 0.9994 Processing i = 1250\n",
      "1363/1875 [====================>.........] - ETA: 19s - loss: 0.0016 - accuracy: 0.9994 Processing i = 1375\n",
      "1489/1875 [======================>.......] - ETA: 14s - loss: 0.0016 - accuracy: 0.9994 Processing i = 1500\n",
      "1613/1875 [========================>.....] - ETA: 9s - loss: 0.0015 - accuracy: 0.9994 Processing i = 1625\n",
      "1738/1875 [==========================>...] - ETA: 5s - loss: 0.0016 - accuracy: 0.9994 Processing i = 1750\n",
      "1863/1875 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9994 Processing i = 0\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0016 - accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer=sgd,loss = 'binary_crossentropy', \n",
    "              metrics=['accuracy'] )\n",
    "\n",
    "History = model.fit_generator(myGenerator(),steps_per_epoch= math.floor(60000//batch_size),\n",
    "                   epochs =epoch ,callbacks=[reduce_lr],  verbose = 1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def H___ (history):   \n",
    "# #     plt.plot(history.history['accuracy'])\n",
    "# #     plt.plot(history.history['val_accuracy'])\n",
    "# #     plt.title('model accuracy')\n",
    "# #     plt.ylabel('accuracy')\n",
    "# #     plt.xlabel('epoch')\n",
    "# #     plt.legend(['train', 'test'], loc='upper left')\n",
    "# #     plt.show()\n",
    "#     # summarize history for loss\n",
    "#     plt.plot(history.history['loss'])\n",
    "#     plt.plot(history.history['accuracy'])\n",
    "#     plt.title('model loss')\n",
    "#     plt.ylabel('loss')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train', 'test'], loc='upper left')\n",
    "#     plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
